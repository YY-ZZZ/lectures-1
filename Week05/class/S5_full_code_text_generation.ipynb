{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_keras_text.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "mX_c22UkrhBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3VLU_13ZrlWw",
        "colab_type": "code",
        "outputId": "c6251d93-2704-458c-8762-cba14c985fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "text = open('trump_speeches.txt').read()\n",
        "#text = open(path_to_file).read()\n",
        "vocab = sorted(set(text))\n",
        "vocab_size = len(vocab)\n",
        "print('Data has {} characters, {} unique characters'.format(len(text), len(vocab)))\n",
        "print(text[:100])\n",
        "\n",
        "# create character to index dictionary and idx to character numpy array for all unique characters\n",
        "char_to_idx = {u: i for i, u in enumerate(vocab)}\n",
        "print(char_to_idx)\n",
        "print('The index for lowercase letter Q is:', char_to_idx['Q'])\n",
        "\n",
        "# To decode the output of an RNN\n",
        "idx_to_char = np.array(vocab)\n",
        "\n",
        "# turn text into integers\n",
        "int_text = np.array([char_to_idx[i] for i in text])\n",
        "print('{} --- are mapped to --- > {}'.format(text[:17], int_text[:17]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data has 852417 characters, 92 unique characters\n",
            "Thank you so much.  That's so nice.  Isn't he a great guy.  He doesn't get a fair press; he doesn't \n",
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '=': 26, '?': 27, '@': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, 'Z': 54, '[': 55, ']': 56, '_': 57, 'a': 58, 'b': 59, 'c': 60, 'd': 61, 'e': 62, 'f': 63, 'g': 64, 'h': 65, 'i': 66, 'j': 67, 'k': 68, 'l': 69, 'm': 70, 'n': 71, 'o': 72, 'p': 73, 'q': 74, 'r': 75, 's': 76, 't': 77, 'u': 78, 'v': 79, 'w': 80, 'x': 81, 'y': 82, 'z': 83, 'é': 84, '–': 85, '—': 86, '‘': 87, '’': 88, '“': 89, '”': 90, '…': 91}\n",
            "The index for lowercase letter Q is: 45\n",
            "Thank you so much --- are mapped to --- > [48 65 58 71 68  1 82 72 78  1 76 72  1 70 78 60 65]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7KEhkY1Mr5ua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_input_target(data):\n",
        "    input_eg = data[:-1]\n",
        "    target_eg = data[1:]\n",
        "    return input_eg, target_eg\n",
        "  \n",
        "\n",
        "def loss_func(real, preds):\n",
        "    return tf.losses.sparse_softmax_cross_entropy(labels=real, logits=preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S5xPwtoKtDGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "        super(Model, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = tf.keras.layers.CuDNNLSTM(self.hidden_size, return_sequences=True, recurrent_initializer='glorot_uniform', stateful=True)\n",
        "\n",
        "        self.output_layer = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x):\n",
        "        embedding = self.embedding(x)\n",
        "        h = self.lstm(embedding)\n",
        "        prediction = self.output_layer(h)\n",
        "        return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SgppPLsXr6z-",
        "colab_type": "code",
        "outputId": "a65e24a3-1779-42bf-cca7-5f4d356eb878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "cell_type": "code",
      "source": [
        "seq_len = 100\n",
        "sections = tf.data.Dataset.from_tensor_slices(int_text).batch(seq_len+1, drop_remainder=True)\n",
        "dataset = sections.map(split_input_target)\n",
        "\n",
        "# create batches and shuffling them\n",
        "batch_size = 64\n",
        "# buffer_size is the number of elements from this dataset from which the new dataset will sample\n",
        "buffer_size = 10000\n",
        "\n",
        "hidden_size = 1024\n",
        "embedding_dim = 256\n",
        "\n",
        "rnn_lstm = Model(vocab_size, embedding_dim, hidden_size)\n",
        "optimiser = tf.train.AdamOptimizer()\n",
        "rnn_lstm.build(tf.TensorShape([batch_size, seq_len]))\n",
        "rnn_lstm.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py:132: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  23552     \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm (CuDNNLSTM)       multiple                  5251072   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  94300     \n",
            "=================================================================\n",
            "Total params: 5,368,924\n",
            "Trainable params: 5,368,924\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lhnazzcZ4mpa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# use tf.train.Checkpoint to save the weights of the model after training\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "# Checkpoint instance\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimiser, model=rnn_lstm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72vE0zy2sK3s",
        "colab_type": "code",
        "outputId": "cf31b579-2d7d-470f-8d5c-de8165955eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2365
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "loss_list = []\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch:', epoch + 1)\n",
        "    data = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "    rnn_lstm.reset_states()\n",
        "    loss_per_epoch = []\n",
        "    \n",
        "    for (batch, (inputs, targets)) in enumerate(data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = rnn_lstm(inputs)\n",
        "            loss = loss_func(targets, output)\n",
        "        grads = tape.gradient(loss, rnn_lstm.variables)\n",
        "        optimiser.apply_gradients(zip(grads, rnn_lstm.variables))\n",
        "        loss_per_epoch.append(loss)\n",
        "\n",
        "        if batch % 100 == 0 and batch != 0:\n",
        "           print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, loss))\n",
        "            \n",
        "    loss_list.append(np.mean(loss_per_epoch))\n",
        "    if (epoch+1) % 1 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "      model = Model(vocab_size, embedding_dim, hidden_size)\n",
        "\n",
        "      checkpoint = tf.train.Checkpoint(model=model)\n",
        "      checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "      model.build(tf.TensorShape([1, None]))\n",
        "      # Generate text from trained model\n",
        "      print('Generated text after {} epoch training:'.format(epoch + 1))\n",
        "      text_generated = []\n",
        "      start_char = 'I'\n",
        "      generating_len = 1000\n",
        "      # convert the start string to an integer\n",
        "      start_int = [char_to_idx[i] for i in start_char]\n",
        "      start_int = tf.expand_dims(start_int, 0)\n",
        "      \n",
        "      # Low temperatures results in more predictable text.\n",
        "      # Higher temperatures results in more surprising text.\n",
        "      # Experiment to find the best setting.\n",
        "      temperature = 0.5\n",
        "\n",
        "      model.reset_states()\n",
        "      for i in range(generating_len):\n",
        "          predictions = model(start_int)\n",
        "          predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "          predictions = predictions / temperature\n",
        "          pred_id = tf.multinomial(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "          start_int = tf.expand_dims([pred_id], 0)\n",
        "          text_generated.append(idx_to_char[pred_id])\n",
        "\n",
        "      print(start_char + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1 Batch 100 Loss 2.3137\n",
            "Generated text after 1 epoch training:\n",
            "WARNING:tensorflow:From <ipython-input-7-ad3bf7bc2995>:49: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.random.categorical instead.\n",
            "I\n",
            "éd ang, you don the doing to wall the going at be hate, I are fan the met the lant alle the sare then wase the ping the and the pere thing the caike save the gad the hat eally verace thith they he the we rethe an the seand the son the war the and I dout the cof the wand gont thith it thored res onde the the the store the wat the the sale tho ron thes meat in the set and the Chis meve the beser fo and tha ken the hasting. The wave gout that be’s of the ping to but and on the will of to ment the sone gor I and the mere son that we thay And and to hant ant at they the and the wald you ve the meany to beve now an the arering thay wally wo wat the sere pout the the we wint the wand that the kant io has and the wave on the the the ke bering to of the seonde theret. The hat wa wand to mant be hachary and and when’s and they thing the the prore if the the gont the youte thay I what ware the hand the anow the wist ou leand ind thes I of thing the the the pespere wave and were the and ating of \n",
            "Epoch: 2\n",
            "Epoch 2 Batch 100 Loss 1.7588\n",
            "Generated text after 2 epoch training:\n",
            "I Afw.\n",
            "An’s bond to caring the whing on the pure fous the and I whe deve sous go the wat cat the ging to have anithe be finger the in weas the sereang and the save the pere list the peresans aod ith when’res the han’ve ind the what se pare the thing the thing the peaved at the pone and they and the wer ve ing tol to and you gon the we’r to ke sout – Poum the the pust the be ghet go the seca. I win’s sat in the ande hare thing the soing the the doun in the ther the wave go wank they ore bo going thing thing to be me bechering the betill yout an the there save the wave the weve whe wher the and and the had thet calling the sople it and I mave they beale, I wank in the coute sou gout and the wan, I and the weand and the warke and the peres the the ave to be salle gove and be rererer in there and ander and we perand tha liding and the thay we wate sating the the the the ger atse there and the have in to he prot what in mest. I dout so thing to knor sha perses in the and. I’d on the hithe th\n",
            "Epoch: 3\n",
            "Epoch 3 Batch 100 Loss 1.4467\n",
            "Generated text after 3 epoch training:\n",
            "I\n",
            "SI’rd ghe’n seve sat and it on the is sots the pon the and yout to gon tho let the the mes in the ting to had the meve in the gore hian trey gowe ind the hath an the doun the prove and it sen the hey ound w and the the the what at thet wale wima to and to de hand wo have dore – shat hat the suve at ther anding to beyant the heve non the at the the gore’s ant it becare gore hrate stous go the and that the and the wa ke and the the preding the ard the and do lace ald the wo wat they we pall merest the dore the soing and the we ment the bey and sat and the wane to the dead gore the same pecendo way whe son the seat of this ther the sen the the and ot thery Yo the at the goike to wan the wery and I doun the went the it the puthe dom ind of in the the was gor be mice thing the wang the’s and the wan we hent it the sat lerat, I and the wane and and the what the and the and we the dent the here thing the don what and. I’s the peis go and be the hat’s dound ane whe and to ned on the seand is \n",
            "Epoch: 4\n",
            "Epoch 4 Batch 100 Loss 1.3136\n",
            "Generated text after 4 epoch training:\n",
            "I fhand the heve the wa the and the s out the sist on the her in the and and the – and the wone gout on they whe’r go wath he won the the the we whe sast the seve and the the and at and the pere ino gores sing at the sing thend it we wale gout I and the tie sant the the pend they will the you d on the peally of the the wa the bunt I the’s the whan the here we was sat hand – thery I buve at and at thing the wall thing the and of in mecallly and they a dot the thet and we that sat ther end the wes the dove we and at thith the then’r got the the serent and he wis haste thith we wing the lout re fount the pont the the the wess in the prith the sig the gound and of ond the the and the tou ghang the way sata that sat in ther thes all to hase de the in thare and the pon thay abe gout in the I ware wave goun that and the sis the that’ tore thar cere asd of ther wa going that wa the and and the and the pore the. The goo thet the don’t the gomere and and the wat they don the wathe and ig the lede\n",
            "Epoch: 5\n",
            "Epoch 5 Batch 100 Loss 1.2737\n",
            "Generated text after 5 epoch training:\n",
            "I\n",
            "–\n",
            "Bu\n",
            "Whing to whe gout and that and of inant the the colling at the liged in the what ave the wast at wing the and they herpan that at the she poull at in we preat dery ware that and tre peress in the ave siand wa hand of the wally so bingats at and of meves cound and the we le thith bere, I that ware ame the hacande af the beve ther fiing of there sigt the wes and recand in the heve be ghen won’rs is ind the then wer aver beca the co thes wave peat then the pourt the the pene the that the me thot the the sent then con they Wery wing to cant thing the we ans the ding the waik cout we salle to the the peand and we pery at whet in that and the pres we hat se the the some.\n",
            "You ke have the we the thint and Ave the prece fon thant the he gou the in the the saing that and out se the bit wa me thit e arit in the prout the rethe they heat the arding the wertre and to list the thes that I sas the res and the the sing at to kal the whe he son’t the asey ponith nom in of the sere the lest er the\n",
            "Epoch: 6\n",
            "Epoch 6 Batch 100 Loss 1.1955\n",
            "Generated text after 6 epoch training:\n",
            "I how and the peread an ther the ked and hast and be pererirt roing not it sing to hing the the peno geve here and thing the keve sats the fat they bo beoing that the the parite and of cata that we king the lople an the sing to the in the athe saling and walk go wer and becale it the we and the save — the we the come the wing the deret. I’s wank the mes pely the we mivery and be the the soon we we’s sto ke to the wisisn I don the and so mige the sang e of on. They wele he ave and the was bith me hapl at wiy srith whe he inst the walling you peond the the sen and the bend I tho there sas the wer as the there in the whey the we puste thent it ous ald the lecing the be the here callebe ar tore found in wand I sand thing we and it I wave the goul ave ave and wingering the were in they wink be you an wo the sabing they and the sica the the rease don that whe wale there antine wave and the’s the nout seal the the’t in and the wion to the it the wan’s levery font ens ankes the athe soid the pe\n",
            "Epoch: 7\n",
            "Epoch 7 Batch 100 Loss 1.1565\n",
            "Generated text after 7 epoch training:\n",
            "I the rof and the that sat the the and go pand of thar ges siand sid at’res and rese arereres and – whand they whe beon the pund and tout the wank the thats and and ore of oud an the the sor the is and the ak and that gos und the the mere in the Weope ley – the wand me and in the’s the we and to the ave lis palle in cout I whe ang the case not sat and thit’s in the we ghit the the and the githe nout the preat – there and end at that we the have And I wave the bere in the wan the wad wase the sor thes’red ind and the whe way the salle the they And I dere pollyry thend gont the son tit ant the wan singe to and oney to ke the the seme leve and and and eve and the seople gon tha there and whery wand the ses thet’s thes thing the sere and thet weve sore and and wo the doun.\n",
            "And I’ve we the sand some ald the seve and the wame herige ve the and in the wang to paope to mat to ther the caon thit sat and and the ped ig to nort to ou the thit wave and the the wave tory he sand it sere caling the p\n",
            "Epoch: 8\n",
            "Epoch 8 Batch 100 Loss 1.0803\n",
            "Generated text after 8 epoch training:\n",
            "I.\n",
            "WAAl han dive and wa saed I over the wan the pere selling the and at thes and the pive the wat in tha buve the wive it tou and te dot en and that there and tist rowe an mort of wean to jut the ke and ave and the wo se the sere hant to whe and ave and the sen the sive theas we seand the the walle and and then an thing to yous the was they wo hate as the heve thing in and ther an whe perere and it and at afing at ant the seve and thay the preate of thing thing wo sin the are – ind the the merery it the and the the sathe thant and the we hend that an to hat bering there wey hent sith there going of the sut tha seon the we save the kes dive gor in the d ou her the the cant that whe have the have the dost at there as ont the we mat ha pestere and the cous in the list ther and the tik an wan sant ther and it and I the cand th was the have you do that at we seo the ther and ind ut the wint to ha pront the wame the poulle taly And there the gone the the and an and and at win the and the wat \n",
            "Epoch: 9\n",
            "Epoch 9 Batch 100 Loss 1.0588\n",
            "Generated text after 9 epoch training:\n",
            "I-I goun that and the the gorile the pall. I’m they whe whe share and wind the mat tout and whith the way andithe at the wathe in thes and that whey’re tha goun the gout fot the we wion wo sally and bucer and at thith the ond thas in theale they the want so the dere and the sas and – I wan’t the reand an then sed ave The pound as the an the save we’s thing the aplo cith the the thing the the the and they hank ofade an the thes and the wo the wat at on to hat? The we what dore tore and the whit the rether snore and at it we sace to the and thet wint to he hid the as and the sang and ther they and the ses illite. But and wite way hat whey reale and I the thay the gere and they as.\n",
            "I wat thing the and of in the and or the thame the the peount ow the and I Pas the the avery and and to hat yoe the kes the thery do hath the we gave the ave the prout the s and and the the rere thing the pane whe pere cicast. But – we’r de themen be pone thes sally ind ally on the maikn to he fut thet I deve th\n",
            "Epoch: 10\n",
            "Epoch 10 Batch 100 Loss 1.0182\n",
            "Generated text after 10 epoch training:\n",
            "It’pdery and in tout the and at meave in thead and the we’t tornt and on wicant. I’ve los yout the heat sasy the gout the pout that and the’s on the sat thing tis on the wathe gout the bece ine the dige sing to ghe to kn they at that the you ling the aca the and the it erase the besating wo that and the don the the waele and in the wint the and it the sacy the becart of and ave the pront the the dont we seste dey doo I don’t the the aly and yomere and that thing the prething to wand the ware and merith – I wo ke soust the re the ande att and the peally th whe’s end at at we seve go prererto in at at sere the sere camese the were and the at int ave I soing at the pare ave serere the thes and and ind it and on wa be the hat. Thet and at ant they whe per tou ther this at the the pont the peope be picale and ald he prone going the meca dicaly hat then thece anding the and the wang eve ous the I walling at they Med th they be the are and and we the wally aple the the sall cat and the lave an\n",
            "Epoch: 11\n",
            "Epoch 11 Batch 100 Loss 0.9951\n",
            "Generated text after 11 epoch training:\n",
            "I\n",
            "Yous.\n",
            "We that the mere pit the we thing the bis cerle at his the Meall and the have in the deon the going ther have gous I dout and to that and you ge’s ther ard in as thith the thing to wan that thing the wid ke and the the the in the were and I And ta sores weas and the perer the sard and the was the pore and be purit he proursts. We heve they’re were going the’r anding the pevere sas in the and and the sant the and ther ant the wint the the wen the thay I whe prontt the the peress. We the pe came of the reaple thing the wean, theres wast an the heve andot and the the thing thes aber the sall the the and that an the hast thing the becant the wast in the hat it and the wath the Than we and the weall thead and you dou knot and be ind the I ald tou halle and of meve yor the he the herd ant the wast and at the the the sas the erere priste more.\n",
            "And at the the and ous the thand at andstre im tone the sore the the and the haig wrome bevere and an the the ant they way the wank ave I they w\n",
            "Epoch: 12\n",
            "Epoch 12 Batch 100 Loss 0.9418\n",
            "Generated text after 12 epoch training:\n",
            "I’s on whe the he perene the soply ave and of in wat whithe gout the and the Reane the hing theme they that the perestan and the the papy and I wo ke doon the pedithe the wore an. I the want the ware and it’re we the penite to and the thet wo ant of the in and of the ale chist ther wery to we allican the pave and the the gound to than wa gout the ave of the he afdiges appint everad andy at an the wand the verid of and to he pere callithe and the none af tou we go the the to meste dor in that and beling the sale we sane they wo hat ind the we the erand the and the ind ave the and becarit is and the bellyit s an weall gor wing the and the plest an the save thing ath the heve lidid ar athed tot in as thing tor the peace aterit of a are tret and the thay seant so the the and we and the pere ond the wand they way the mere that of the wace dean thit’s wo le and co mere the thet sis the pant and the proulis. We’s in the the sans and we coud and and the the heake and the the wean the thing the \n",
            "Epoch: 13\n",
            "Epoch 13 Batch 100 Loss 0.9149\n",
            "Generated text after 13 epoch training:\n",
            "I‘:\n",
            "A9’jd do so calles the ghe core ther and at de aveing to ke Ane nous wo hall ald the bell in the that we hat and the we wa ver of the pithe. I the have they sith the pore and do gone tre the he toing to here the perith and the ke have wa and of bust the alling and andy the don be ceaplly he sermering the the we the ment tha doned I shan the ton the were and the pally ware going that and they the we pere they the keas cat in and that in gon the penithan the and the cone the the wabe that the porat be at the the we font than where and to te and the way he peat the there the the weve sere the saile in the we the mes the the sous an the and to thes the thay, I and the and they I meand Ind weas the bestring to ke the list the hecates and the meste the want the and thith thiy me the alling to wan that in ate the wen we ast the pere bid the ghay the and the the dothe and cere porant and the mrecpent And on and the ally the he hang to they’re prong ve licand it of an. I hask and the talle t\n",
            "Epoch: 14\n",
            "Epoch 14 Batch 100 Loss 0.9208\n",
            "Generated text after 14 epoch training:\n",
            "I mave and bote the have te and the prout the thay and of ave the peinet in to nome the ther thing you knou the athing the hend it the the wane they I whan and that the cave they is and the was the pount of the prere the I wand the the the the was and and on they she pont the fat the tho the pecery the the have and aturer is ther ing the the thing the ploit on, an’t it and no wa the the keve fou sit at were and I cave athe sint there asing the hang to whit and the he peand bet the the pean the han in to han we somed if Meppen thes wave me the peret the the pailling the and seas the whe kes on the ave to the the dout the are in thit cat on thes thing the and thend the sattes. But the pe perling that and they’re and gouke all be pople gaming to that we what wist se sathe forednow dand the we pent the reave in in the whe save at and of and thit wall I mang — way the’s wat tho have and the soun thing the pere be perith and the reant ston’s ou ke and there and whe pere and the seald and at i\n",
            "Epoch: 15\n",
            "Epoch 15 Batch 100 Loss 0.8429\n",
            "Generated text after 15 epoch training:\n",
            "I\n",
            "cDMikl in the ke the the sat the lees se we proisg the want, I don’t thay thang cate the thand they thang the sing to the I hane seve beas the the we ware the anteres allingt. And whe heve becand se med the ping the lige the in fit sist the sealling thet the hingt on and the prete and wo be thith the bunt mithe forere sim and we hay hith the want the cathe sore and and yo hast that thing of ous in wher sall wint thay meand to se cares were we ther in the pent the gore and se and I the have the wane the hant. And I whay I wan’t tha go the prere in and the penot the the we wing thit that don the dide ave erering the 1the was the thet wake an thiy the now ve lise they sath the in the weade gor ant whe wo ghe the wean the peos, whey’s an in the mory and at wint the have the thath they to we pront to hathe the pealle ave beon the the the sere wall ave in the palide that the der and.\n",
            "And I dor going the that cace they mand tha thet whe thing on thing the thit’s they the weve wass and the pr\n",
            "Epoch: 16\n",
            "Epoch 16 Batch 100 Loss 0.8384\n",
            "Generated text after 16 epoch training:\n",
            "I\n",
            "FOmponke wame do we save I doing the he sropent? The whet’s and at the the the bening the sere wing ar tou the ame thing the have the keally and they thes and then the the ned is seing the they wall to the were and tout fol the the yound there ande and thint the beate the deave non the per the port. I wall, Ire wen we and the ther poun the the $reald will tha we porelly the whe and at and whe the and it it the acald it of the wica the the cand, we hey int ats in tore and the ve perat to and the woing to hang that save and I dome and thing sith the way in want ut cout he ses the there the pean ther in micing of if the and the the ker that wall is and that so the and on that it at the gous the sand the wave seat on. I don’t do know wat sto wand so the son thane the yound to the and the save that and of the and the wast it a athe we peat we whe have the pered and in thet some tho in the ind is they whave gow and and the have tous wat e boing the going the they see dont wo cave the peone \n",
            "Epoch: 17\n",
            "Epoch 17 Batch 100 Loss 0.8331\n",
            "Generated text after 17 epoch training:\n",
            "Ix’veres and to whe hes the and the. I leve hestine meate the meared the thare berd it sond the have and of wheig that the and the sores in thes in and the bigt and the and thes and the thes at the and the pering the ke ousthe san thed an that it that dout coust the andigo the prond and as the mey jut and and Chey the they whe and to the then arate and and the beve hithe sally and the sith the I meall and he and toun the fere and the’t the pease and the theme the and the gee to the there in whe hata than the sant the ke in the that in the gonet and the hath to meeperand the loople in the thate go pors thing the the they the sing the wave what at the promang the the we hang and the going to the the pace in the we hill and in at the gond and waikn with ave and the kent in they we’s they Malling to hey and they wis te poret and wher at in thes the pere thing tho de and ast Che deve ther it the count the caoce thing to end the dount the tout he pere and I dou and wing they it the t ouk and \n",
            "Epoch: 18\n",
            "Epoch 18 Batch 100 Loss 0.7665\n",
            "Generated text after 18 epoch training:\n",
            "IN’ve ghor and becoust the prope in the there and the the $1 I whe meve yout the the seand the wand the hapled and of at the the in whe wank an’t on the that thith perse sime an wad the here ve won stot meat the poold at the silles.\n",
            "Sea going the wanke and I souse ous going the wat at the preas the pret becant the gon and the prople. You go the pere the an the and the sive and and we ouver and to in and the I I what the mene and we wang thet se are ind at and jot and and than to heplest in they the a beve hat in the meme the poinge thithe and it and the we hant is the the the ard ar the to have south they and the sonk the hang thee and gouns the pround thet wame and bo andout the pont and whe dere and the panting the wing the and th the heve and the perathe alle thing to we nat it that dout it the hill the prepe calle And I have som ind they’re and the sront. I have the wem the seare an. I dou hate dow the and to the beane of and the and the wank gores and to math at tor at ig thing tha\n",
            "Epoch: 19\n",
            "Epoch 19 Batch 100 Loss 0.7719\n",
            "Generated text after 19 epoch training:\n",
            "IjElI\n",
            "Oha wave gouth the say and bo care fout I in thit’s the ke mo kert sing at it the have going the the wall they meas the froica tha de sorlent do cast and the wer and thit and and the don wat and icary of carperisars and yo lot and and I the wery to meve the and whe the tha ke sore and our thing ond Ko in the ing the merest thing, we’r an the have we many ther gois so the sis the and the proinge watt the the to ant that wat an. I dot’r they I the mane and at the prone the was at ar at thing and ther were and and to thing en fut iat and I’s mead ca the’s ave hat the bever thes save the pont it the disge the the ko pand that and weve an the sis at in beat the and the wank and at of thing it the and thet the andery thit ano ther. I dove ke mave ther wing the and whey and to ouve ore te never goun the the pes athe the and ave ald and ill and whar gou the was in the hay there and at wo perent the Chant and the sere the pere and the end what so gely of the Orereand the sating thes shand \n",
            "Epoch: 20\n",
            "Epoch 20 Batch 100 Loss 0.7155\n",
            "Generated text after 20 epoch training:\n",
            "IN&BAky.\n",
            "Whey wane ald the sout ke wrot and I diin the were and of theve bous the and and out they’re toing to hag the sererasy all the the ant the gous hant thing thay we any the ses the sin the pering thing the at ous I we’r it say and do meand to he aid hat ith at and ther and the weand the and the pereand the pale the digh the poing ther and of the the seris thet and the in thing gou we the the wast the pace on wint thay have is the preale tha the prone you gor that the will that the the pand was and the herut the sile they wan’t the hant it the reve soule have the that the goust and the hating to that salit and wo we the and the doill it thes thase pime frith to an the the bertres at thing that the pant the cout of the pevery of whe paig and they dome than we the singt to se and and the peat ther and the peste the ave and the wat an the the her care the restent ve lake als youre and on to sand we hing to ront the the to go that wher thes so the the thes and thing in wat the peors a\n",
            "Epoch: 21\n",
            "Epoch 21 Batch 100 Loss 0.7141\n",
            "Generated text after 21 epoch training:\n",
            "I\n",
            "Amvxead, I and the we’l the the bove found the het in that the want the sas dore a hith al wint they jut and I werpre hat be the save an the preats son the bey in sion the that and the peon the besthert of and the and I wand you going the and at fid the and to the thing and the hest whans the sere cou thing to wo nowey to de the gout ther mure ind thes there and and the the wave dow they wing the and thist the and at and it thave ave and in the ghead ther wat all the whay and and the seing they we pevery meat core and the rent ow the beting the caret the won wat it the wave at and that the to the and dout cheprey ruthe dous the pees is the the and it enow the seapling the prere corere wo se the have ath the ssat and at the ande whe ally.\n",
            "The pathe the kes of to ant to we save the the we pore of ther and the poed thay gor be hathe and at the thist have ou hathint at the we a care ther bat the salle he pacang the int at thit ste perant he and and at the thing the ald the wes and and – a\n",
            "Epoch: 22\n",
            "Epoch 22 Batch 100 Loss 0.6896\n",
            "Generated text after 22 epoch training:\n",
            "I’’'ng wore waw tha beve pean the they wo leme that whe bether seas – I dhe’re the wand to bith thave berere me core going the leme the sist at the the what and tor and the the want the want we whe pang to be the pere to becand the alle the weaple of un wint and the and and that be the that ant that ig the pret the the wat the cout in the sa ming the sein the don to he and of the the wisn the hand and and the and the and that se poster ay and it and the Re satis and Yous the the leve the the the and we were and of the’s and wilken we and the acter at and and to wa ke he sere the in the to th the pone at in the andithesand to than geas that sot coull it the ceoperer. And the haca dome win the the wery out the be want the hatt in so the he ape the sant I dont they win wo puve toing it the gore. The the hat hat the whing, mo ant thing te the thire wor hane bere ast at in thing the sond wo we prous in the atr the I tound they ing the tame the thith they’re are the gere meant. 6t’r the the h\n",
            "Epoch: 23\n",
            "Epoch 23 Batch 100 Loss 0.6539\n",
            "Generated text after 23 epoch training:\n",
            "I8\n",
            "—\n",
            "SPSThing they the ke bend and the weve the pecing thit we same they the now ond gore. I wam wey’r going the the whon the pont thing ou hand and ave wing the thing to we and best and ther and are and and ald it the gout the wat’s the merens Weshe s the pet in whes the have cant the ont the the the pitis go of thing the the s ous the welle dere sont the beve the sant do thing ther ded the gon the wous and the cant and in wist de hate toing ave to thith thith at ally.\n",
            "Weve anding on ther the hate she the then thes hat and we ton the dond the ond ond Chat sis the ending the perpered ans thit and the cant thit’s the the and to we ping to the wan ther wering and and ave the thing the sout and at wou gous and and the going ond the pinge pillit, I dome we the the pris thing we and the that sor thit ore to the prpelle dout th the and ching the wan’t that the dont and the pant we the wene the thes thits wan and that sit thit thive and and I thet the king the you gore thing them wing thith I \n",
            "Epoch: 24\n",
            "Epoch 24 Batch 100 Loss 0.6271\n",
            "Generated text after 24 epoch training:\n",
            "I= wout met and the pand the hare the serere an the the sere have and me pront the we that wit the heale the sent the thet ren the the gon the to the we the thet and the peve at sout and they weag se that dont re athe sound and they the have in the hast the the pely ind the wang lo orery the we poon and that doing to wall the kecant they’re as the pesing thing the walke to bed of the what go and the the the peald and the the pere hring in the the ave the merpend you. And they’re the beverend the waing and of thes wat me’s the cous and the the wave mede ind the deris, do pavet ald at the whe were. And dout, led the wang they and the sathe and and and at wing the the and the wan the hat and the sere hice and the peere going of to kave the beve the the be some the they wery it wide tot and the and sous gout the we an’t that don whou hericad. And you per at thay and the wal if they beve becare bat ing perping the sen thet and the wang the we the we the satre sis and and and they we waing th\n",
            "Epoch: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oj4hK4be6x2Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  import matplotlib.pyplot as plt\n",
        "  \n",
        "  plt.plot(loss_list)\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Number of epochs')\n",
        "  plt.ylabel('Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}